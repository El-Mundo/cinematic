{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deprecated due to poor performance\n",
    "\n",
    "# Get all scenes with more people detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 宋士杰, 11:23:33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb8591b90c9422a92eeacfa809ede08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, max=5820.8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 157\u001b[0m\n\u001b[1;32m    154\u001b[0m \t\u001b[39mreturn\u001b[39;00m number, thumb\n\u001b[1;32m    156\u001b[0m \u001b[39mfor\u001b[39;00m filename \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m../../Temp/*.mp4\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 157\u001b[0m \tprocessVideo(filename, \u001b[39m'\u001b[39;49m\u001b[39m./Temp\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m./thumbnails/cache\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[3], line 53\u001b[0m, in \u001b[0;36mprocessVideo\u001b[0;34m(pathIn, pathOut, thumbPath)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m pos \u001b[39m>\u001b[39m total_secs:\n\u001b[1;32m     51\u001b[0m \t\u001b[39mbreak\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m vidcap\u001b[39m.\u001b[39;49mset(cv2\u001b[39m.\u001b[39;49mCAP_PROP_POS_MSEC, pos \u001b[39m*\u001b[39;49m \u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     54\u001b[0m p_bar\u001b[39m.\u001b[39mvalue \u001b[39m=\u001b[39m pos\n\u001b[1;32m     55\u001b[0m p_bar\u001b[39m.\u001b[39mdescription \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(pos)\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mint\u001b[39m(total_secs)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from IPython.display import display, Image\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import glob\n",
    "from ipywidgets import FloatProgress\n",
    "from datetime import datetime\n",
    "\n",
    "TIME_INTERVAL = 5.0 # second(s) for down-sampling\n",
    "PEOPLE_THRESHOLD = 10 # number of people in a frame to be considered as a crowd\n",
    "\n",
    "w = \"YOLO/yolov7.onnx\"\n",
    "cuda = False\n",
    "\n",
    "#YoloV7 attributes\n",
    "videos = []\n",
    "names = ['person']\n",
    "colors = {'person' : [242, 82, 141]}\n",
    "\n",
    "def processVideo(pathIn, pathOut, thumbPath=None):\n",
    "\tVIDEO_NAME = pathIn.split('/')[-1]\n",
    "\tif VIDEO_NAME.endswith('.mp4'):\n",
    "\t\tVIDEO_NAME = VIDEO_NAME[:-4]\n",
    "\n",
    "\twith open('./crowd/processed_videos.csv', 'r') as f_object:\n",
    "\t\ttext = f_object.readline()\n",
    "\t\twhile text != \"\":\n",
    "\t\t\t\ttext = f_object.readline()\n",
    "\t\t\t\tif text == VIDEO_NAME:\n",
    "\t\t\t\t\tf_object.close()\n",
    "\t\t\t\t\treturn #skip processed videos\n",
    "\t\tf_object.close()\n",
    "\t\n",
    "\tcurrent_time = datetime.now().strftime(\"%H:%M:%S\")\n",
    "\tprint(f\"Starting to process {VIDEO_NAME}, {current_time}\")\n",
    "\n",
    "\tcount = 0\n",
    "\tvidcap = cv2.VideoCapture(pathIn)\n",
    "\tsuccess,image = vidcap.read()\n",
    "\tsuccess = True\n",
    "\ttotal_secs = vidcap.get(cv2.CAP_PROP_FRAME_COUNT) / vidcap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "\tp_bar = FloatProgress(min=0, max=total_secs)\n",
    "\tdisplay(p_bar)\n",
    "\n",
    "\twhile success:\n",
    "\t\tpos = count*TIME_INTERVAL # seconds\n",
    "\t\tif pos > total_secs:\n",
    "\t\t\tbreak\n",
    "\t\t\n",
    "\t\tvidcap.set(cv2.CAP_PROP_POS_MSEC, pos * 1000)\n",
    "\t\tp_bar.value = pos\n",
    "\t\tp_bar.description = f\"{int(pos)}/{int(total_secs)}\"\n",
    "\t\tsuccess,image = vidcap.read()\n",
    "\t\t\n",
    "\t\tif success:\n",
    "\t\t\tperson_in_frame, thumb = get_person_count_in_image(image, w, cuda=cuda)\n",
    "\t\t\tif person_in_frame > PEOPLE_THRESHOLD:\n",
    "\t\t\t\tcv2.imwrite(pathOut + f\"/{VIDEO_NAME}-{count}_{person_in_frame}.jpg\", image)\n",
    "\t\t\t\tprint(f\"Found a crowd with {person_in_frame} detectable persons in {VIDEO_NAME} at {count} seconds\")\n",
    "\t\t\t\twith open('./crowd/found_frames.csv', 'a') as f_object:\n",
    "\t\t\t\t\tf_object.write(\"{},{},{}\\n\".format(VIDEO_NAME, count, person_in_frame))\n",
    "\t\t\t\t\tf_object.close()\n",
    "\t\t\t\tif thumb is not None and thumbPath is not None:\n",
    "\t\t\t\t\tcv2.imwrite(thumbPath + f\"/{VIDEO_NAME}-t{count}_{person_in_frame}.jpg\", thumb)\n",
    "\t\t\n",
    "\t\tcount = count + 1\n",
    "    \n",
    "\tp_bar.close()\n",
    "\tvidcap.release()\n",
    "\twith open('./crowd/processed_videos.csv', 'a') as f_object:\n",
    "\t\tf_object.write(VIDEO_NAME + '\\n')\n",
    "\t\tf_object.close()\n",
    "\n",
    "def letterbox(im, new_shape=(640, 640), color=(114, 114, 114), auto=True, scaleup=True, stride=32):\n",
    "\t# Resize and pad image while meeting stride-multiple constraints\n",
    "\tshape = im.shape[:2]  # current shape [height, width]\n",
    "\tif isinstance(new_shape, int):\n",
    "\t\tnew_shape = (new_shape, new_shape)\n",
    "\t# Scale ratio (new / old)\n",
    "\tr = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "\tif not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "\t\tr = min(r, 1.0)\n",
    "\t# Compute padding\n",
    "\tnew_unpad = int(round(shape[1] * r)), int(round(shape[0] * r))\n",
    "\tdw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "\n",
    "\tif auto:  # minimum rectangle\n",
    "\t\tdw, dh = np.mod(dw, stride), np.mod(dh, stride)  # wh padding\n",
    "\n",
    "\tdw /= 2  # divide padding into 2 sides\n",
    "\tdh /= 2\n",
    "\n",
    "\tif shape[::-1] != new_unpad:  # resize\n",
    "\t\tim = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "\ttop, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))\n",
    "\tleft, right = int(round(dw - 0.1)), int(round(dw + 0.1))\n",
    "\tim = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "\treturn im, r, (dw, dh)\n",
    "\t\n",
    "def get_person_count_in_image(img, w, cuda=False):\n",
    "\tproviders = ['CoreMLExecutionProvider', 'CPUExecutionProvider'] if cuda else ['CPUExecutionProvider']\n",
    "\tsession = ort.InferenceSession(w, providers=providers)\n",
    "\n",
    "\toutname = [i.name for i in session.get_outputs()]\n",
    "\toutname\n",
    "\tinname = [i.name for i in session.get_inputs()]\n",
    "\tinname\n",
    "\n",
    "\timg = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\timage = img.copy()\n",
    "\timage, ratio, dwdh = letterbox(image, auto=False)\n",
    "\timage = image.transpose((2, 0, 1))\n",
    "\timage = np.expand_dims(image, 0)\n",
    "\timage = np.ascontiguousarray(image)\n",
    "\n",
    "\tim = image.astype(np.float32)\n",
    "\tim /= 255\n",
    "\tim.shape\n",
    "\tinp = {inname[0]:im}\n",
    "\n",
    "\toutputs = session.run(outname, inp)[0]\n",
    "\toutputs\n",
    "\tori_images = [img.copy()]\n",
    "\n",
    "\tnumber = 0\n",
    "\n",
    "\tthumb = None\n",
    "\t\n",
    "\tfor i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "\t\tthumb = ori_images[int(batch_id)]\n",
    "\t\tcls_id = int(cls_id)\n",
    "\t\tif cls_id != 0 :\n",
    "\t\t\t# only keep person information\n",
    "\t\t\tcontinue\n",
    "        \n",
    "\t\t# a person is found\n",
    "\t\tnumber += 1\n",
    "\n",
    "\t\tbox = np.array([x0,y0,x1,y1])\n",
    "\t\tbox -= np.array(dwdh*2)\n",
    "\t\tbox /= ratio\n",
    "\t\tbox = box.round().astype(np.int32).tolist()\n",
    "\n",
    "\t\tname = names[cls_id]\n",
    "\t\tcolor = colors[name]\n",
    "\t\tcv2.rectangle(thumb,box[:2],box[2:],color,2)\n",
    "\t\t# resize to 1/4\n",
    "\t\tthumb = cv2.resize(thumb, (0, 0), fx=0.25, fy=0.25)\n",
    "\t\tthumb = cv2.cvtColor(thumb, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\treturn number, thumb\n",
    "\n",
    "for filename in glob.glob('../../Temp/*.mp4'):\n",
    "\tprocessVideo(filename, './Temp', './thumbnails/cache')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
